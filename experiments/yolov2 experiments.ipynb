{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape, Conv2D, Input, MaxPooling2D, BatchNormalization, Dense, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import numpy as np\n",
    "from utils import read_labels, draw_image, image_to_yolo_input, Object, parse_annotation, Annotation, calculate_IoU, image_to_vgg_input, image_to_mobilenet_input, LabelEncoder\n",
    "from PIL import Image as Img\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: read from config\n",
    "\n",
    "image_width = 416\n",
    "image_height = 416\n",
    "grid_width = int(image_width / 32) # 13\n",
    "grid_height = int(image_height / 32) # 13\n",
    "\n",
    "cell_width = image_width / grid_width\n",
    "cell_height = image_height / grid_height\n",
    "\n",
    "boxes = 5\n",
    "\n",
    "activation_alpha = 0.1\n",
    "\n",
    "object_scale = 10\n",
    "noobject_scale = 1\n",
    "class_scale = 2\n",
    "coord_scale = 2\n",
    "\n",
    "threshhold = 0.5\n",
    "nms_threshhold = 0.5#0.5\n",
    "\n",
    "anchors = np.array([[1.05, 1.65], [2.44, 4.13], [4.01, 8.46], [7.62, 5.13], [9.97, 10.43]], dtype = np.float32) # obtained from KMeans experiments ipynb\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "labels_dir = \"./labels.txt\"\n",
    "\n",
    "annotation_folder = '.\\VOCdevkit\\VOC2007\\Annotations'\n",
    "images_folder = '.\\VOCdevkit\\VOC2007\\JPEGImages'\n",
    "\n",
    "murka = r'.\\mytestimages\\murka.jpg'\n",
    "\n",
    "test_annotation = r'.\\VOCdevkit\\VOC2007\\Annotations\\000113.xml'\n",
    "test_image = r'.\\VOCdevkit\\VOC2007\\JPEGImages\\000113.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['horse', 'diningtable', 'sofa', 'train', 'bird', 'aeroplane', 'person', 'boat', 'bottle', 'motorbike', 'bus', 'cat', 'pottedplant', 'car', 'dog', 'bicycle', 'sheep', 'cow', 'tvmonitor', 'chair']\n"
     ]
    }
   ],
   "source": [
    "labels, labels_count = read_labels(labels_dir)\n",
    "\n",
    "encoder = LabelEncoder(labels)\n",
    "\n",
    "print(labels_count)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tinyyolov2():\n",
    "    layers = []\n",
    "\n",
    "    layers.append(Input(shape=(image_width, image_height, 3)))\n",
    "\n",
    "    layers.append(Conv2D(filters = 16, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_1\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_1\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_1\", alpha = activation_alpha))\n",
    "    layers.append(MaxPooling2D(name = \"maxpool_1\"))\n",
    "\n",
    "    layers.append(Conv2D(filters = 32, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_2\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_2\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_2\", alpha = activation_alpha))\n",
    "    layers.append(MaxPooling2D(name = \"maxpool_2\"))\n",
    "\n",
    "    layers.append(Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_3\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_3\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_3\", alpha = activation_alpha))\n",
    "    layers.append(MaxPooling2D(name = \"maxpool_3\"))\n",
    "\n",
    "    layers.append(Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_4\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_4\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_4\", alpha = activation_alpha))\n",
    "    layers.append(MaxPooling2D(name = \"maxpool_4\"))\n",
    "\n",
    "    layers.append(Conv2D(filters = 256, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_5\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_5\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_5\", alpha = activation_alpha))\n",
    "    layers.append(MaxPooling2D(name = \"maxpool_5\"))\n",
    "\n",
    "    layers.append(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_6\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_6\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_6\", alpha = activation_alpha))\n",
    "    #layers.append(MaxPooling2D(name = \"maxpool_6\", pool_size = (2, 2), strides = (1, 1)))\n",
    "\n",
    "    layers.append(Conv2D(filters = 1024, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_7\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_7\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_7\", alpha = activation_alpha))\n",
    "\n",
    "    layers.append(Conv2D(filters = 1024, kernel_size = (3, 3), padding = \"same\", use_bias = False, name=\"conv_8\"))\n",
    "    layers.append(BatchNormalization(name = \"norm_8\"))\n",
    "    layers.append(LeakyReLU(name = \"leaky_8\", alpha = activation_alpha))\n",
    "\n",
    "    layers.append(Conv2D(filters = (boxes * (4 + 1 + labels_count)), kernel_size = (1, 1), padding = \"same\", name=\"conv_9\"))\n",
    "\n",
    "    layers.append(Reshape(target_shape = (grid_width, grid_height, boxes, 5 + labels_count), name = \"output\"))\n",
    "\n",
    "    tinyyolov2 = Sequential(layers = layers, name = \"tiny yolov2 voc\")\n",
    "    tinyyolov2.summary()\n",
    "    \n",
    "    return tinyyolov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_images(annotations_dir, images_dir):\n",
    "    image_formats = ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']\n",
    "    \n",
    "    annons, images = [], []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(annotations_dir):\n",
    "        for file in f:\n",
    "            if '.xml' in file:\n",
    "                image_exists = False\n",
    "                for im_format in image_formats:\n",
    "                    image_name = file[:-4] + im_format\n",
    "                   \n",
    "                    image_path = images_dir + '\\\\' + image_name\n",
    "                    \n",
    "                    if os.path.exists(image_path):\n",
    "                        image_exists = True\n",
    "                        break\n",
    "                        \n",
    "                if image_exists:\n",
    "                    annons.append(annotations_dir + '\\\\' + file)\n",
    "                    images.append(images_dir + '\\\\' + image_name)\n",
    "    \n",
    "    #annons = annons[:250]\n",
    "    #images = images[:250]\n",
    "    \n",
    "    return annons, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_y_true_from_annotation(annotation, raw_file = True):    \n",
    "    y_true = np.zeros(shape = (grid_width, grid_height, boxes, 5 + labels_count))\n",
    "    objs = [[[] for col in range(grid_width)] for row in range(grid_height)]\n",
    "    \n",
    "    if raw_file:\n",
    "        annotation = parse_annotation(annotation)\n",
    "    \n",
    "    image_cell_width = annotation.imagewidth / grid_width\n",
    "    image_cell_height = annotation.imageheight / grid_height\n",
    "    \n",
    "    for obj in annotation.objects:\n",
    "        obj.xmid = (obj.xmax + obj.xmin) / 2\n",
    "        obj.ymid = (obj.ymax + obj.ymin) / 2\n",
    "        obj.width = obj.xmax - obj.xmin\n",
    "        obj.height = obj.ymax - obj.ymin\n",
    "\n",
    "        row = int(obj.ymid / image_cell_height)\n",
    "        col = int(obj.xmid / image_cell_width)\n",
    "        #print(f'row {row} col {col}')\n",
    "        \n",
    "        objs[row][col].append(obj)        \n",
    "    \n",
    "    for row in range(grid_height):\n",
    "        for col in range(grid_width):\n",
    "            cell_objs = objs[row][col]\n",
    "            random.shuffle(cell_objs)\n",
    "            \n",
    "            for obj in cell_objs:                \n",
    "                best_anchor_index = 0\n",
    "                best_IoU = -1\n",
    "\n",
    "                for index in range(boxes):\n",
    "                    anchor_w, anchor_h = anchors[index]\n",
    "                    #print(f'anchor_w: {anchor_w}, cell_width: {image_cell_width}, width: {anchor_w * image_cell_width}')\n",
    "                    #print(f'anchor_h: {anchor_h}, cell_height: {image_cell_height}, height: {anchor_h * image_cell_height}')\n",
    "\n",
    "                    width = anchor_w * image_cell_width\n",
    "                    height = anchor_h * image_cell_height\n",
    "\n",
    "                    xmid = (col + 0.5) * image_cell_width\n",
    "                    ymid = (row + 0.5) * image_cell_height\n",
    "\n",
    "                    anchor_object = Object(xmin = xmid - width/2, xmax = xmid + width/2, ymin = ymid - height/2, ymax = ymid + height/2)\n",
    "                    #print(anchor_object)\n",
    "\n",
    "                    current_IoU = calculate_IoU(obj, anchor_object)\n",
    "                    #print(f'IoU: {current_IoU}')\n",
    "                    #draw_image(images_folder + '\\\\'  + annotation.filename[:-4] + '.jpg', objects = [obj, anchor_object], draw_grid = True, grid_size = (grid_width, grid_height))\n",
    "                    if current_IoU > best_IoU:\n",
    "                        best_IoU = current_IoU\n",
    "                        best_anchor_index = index\n",
    "\n",
    "                '''\n",
    "                grid_center_x = (row + 0.5) * image_cell_width\n",
    "                grid_center_y = (col + 0.5) * image_cell_height\n",
    "\n",
    "                x = obj.xmid - grid_center_x\n",
    "                y = obj.ymid - grid_center_y\n",
    "\n",
    "                w = np.log(obj.width / anchors[best_anchor_index][0]) \n",
    "                h = np.log(obj.height / anchors[best_anchor_index][1]) \n",
    "                '''      \n",
    "                x = obj.xmid\n",
    "                y = obj.ymid\n",
    "\n",
    "                w = obj.width\n",
    "                h = obj.height\n",
    "\n",
    "                c = 1 #best_IoU\n",
    "\n",
    "                detector = np.zeros(shape=(5 + labels_count))\n",
    "\n",
    "                detector[0] = c\n",
    "                detector[1] = x\n",
    "                detector[2] = y\n",
    "                detector[3] = w\n",
    "                detector[4] = h\n",
    "\n",
    "                label_index = encoder.encode(obj.name)        \n",
    "                detector[5 + label_index] = 1\n",
    "\n",
    "\n",
    "                y_true[row][col][best_anchor_index] = detector\n",
    "    \n",
    "    \n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1222 20:19:08.831570 20888 deprecation.py:323] From <ipython-input-8-5e31b72149f0>:15: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "assume_batch_size = 10\n",
    "assume_grid_width = 3\n",
    "assume_grid_height = 3\n",
    "assume_boxes = 2\n",
    "\n",
    "cell_x = np.reshape(np.repeat(np.tile(range(assume_grid_width), assume_batch_size * assume_grid_height), assume_boxes), (assume_batch_size, assume_grid_width, assume_grid_height, assume_boxes))\n",
    "cell_y = np.transpose(cell_x, (0,2,1,3))\n",
    "\n",
    "#print(cell_y.shape)\n",
    "#print(cell_y)\n",
    "#print('=====================================')\n",
    "#print(cell_index)\n",
    "\n",
    "cell_x = tf.to_float(tf.reshape(tf.keras.backend.repeat_elements(tf.tile(tf.range(assume_grid_width), [assume_batch_size * assume_grid_height]), assume_boxes, axis=0), \n",
    "                        (assume_batch_size, assume_grid_width, assume_grid_height, assume_boxes)))\n",
    "cell_y = tf.transpose(cell_x, (0,2,1,3))\n",
    "\n",
    "#print(cell_x)\n",
    "#print('=====================================')\n",
    "#print(cell_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef custom_loss(y_true, y_pred):\\nc_pred = tf.sigmoid(y_pred[:, :, :, :, 0])\\nc_true = y_true[:, :, :, :, 0]\\n\\ngreaters = tf.greater(c_true, 0.0)\\n\\nmask_shape = (batch_size, grid_width, grid_height, boxes)\\nobjs = tf.ones(shape = (mask_shape)) * object_scale\\nnoobjs = tf.ones(shape = (mask_shape)) * noobject_scale\\n\\ncoef = tf.where(greaters, objs, noobjs) \\n\\n\\n\\nreturn coef * (c_true - c_pred) ** 2\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    '''\n",
    "    intermins = tf.maximum(xy_true, xy_pred)\n",
    "    intermaxes = tf.minimum(xy_true, xy_pred)\n",
    "\n",
    "    interArea = tf.maximum(0.0, intermaxes[..., 0] - intermins[..., 0] + 1) * tf.maximum(0.0, intermaxes[..., 1] - intermins[..., 1] + 1)\n",
    "\n",
    "    groundTruthArea = (wh_true[..., 0] + 1) * (wh_true[..., 1] + 1)\n",
    "    predictedArea = (wh_pred[..., 0] + 1) * (wh_pred[..., 1] + 1)\n",
    "\n",
    "    iou = interArea / (groundTruthArea + predictedArea - interArea)    \n",
    "    \n",
    "    xpred = y_pred[:, :, :, :, 1]   \n",
    "    ypred = y_pred[:, :, :, :, 2]                \n",
    "    xtrue = y_true[:, :, :, :, 1]\n",
    "    ytrue = y_true[:, :, :, :, 2]\n",
    "\n",
    "    wpred = y_pred[:, :, :, :, 3]\n",
    "    hpred = y_pred[:, :, :, :, 4]                \n",
    "    wtrue = y_true[:, :, :, :, 3]\n",
    "    htrue = y_true[:, :, :, :, 4]\n",
    "\n",
    "    xy_pred = y_pred[:, :, :, :, 1 : 3]\n",
    "    xy_true = y_true[:, :, :, :, 1 : 3]\n",
    "\n",
    "    wh_pred = y_pred[:, :, :, :, 3 : 5]\n",
    "    wh_true = y_true[:, :, :, :, 3 : 5]\n",
    "    '''   \n",
    "    \n",
    "    \n",
    "    #loss = tf.reduce_mean(loss)\n",
    "    #print(np.any(np.isnan(xywhcoef)))\n",
    "    #print(np.any(np.isnan(((xtrue - xpred) ** 2))))\n",
    "    #print(np.any(np.isnan(xywhcoef * ((xtrue - xpred) ** 2))))\n",
    "    #print(loss)\n",
    "    \n",
    "\n",
    "'''\n",
    "def custom_loss(y_true, y_pred):\n",
    "    c_pred = tf.sigmoid(y_pred[:, :, :, :, 0])\n",
    "    c_true = y_true[:, :, :, :, 0]\n",
    "    \n",
    "    greaters = tf.greater(c_true, 0.0)\n",
    "    \n",
    "    mask_shape = (batch_size, grid_width, grid_height, boxes)\n",
    "    objs = tf.ones(shape = (mask_shape)) * object_scale\n",
    "    noobjs = tf.ones(shape = (mask_shape)) * noobject_scale\n",
    "    \n",
    "    coef = tf.where(greaters, objs, noobjs) \n",
    "    \n",
    "    \n",
    "    \n",
    "    return coef * (c_true - c_pred) ** 2\n",
    "'''\n",
    "\n",
    "\n",
    "#runningman = images[52]\n",
    "#runningmanannot = annotations[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(anchors)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (almost) complete yolov2 loss function\n",
    "def custom_loss(y_true, y_pred):    \n",
    "    c_pred = y_pred[:, :, :, :, 0]\n",
    "    c_true = y_true[:, :, :, :, 0]\n",
    "    \n",
    "    c_pred = tf.sigmoid(c_pred)\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.keras.backend.repeat_elements(\n",
    "                                                tf.tile(tf.range(grid_width), [batch_size * grid_height]), boxes, axis=0), \n",
    "                                    (batch_size, grid_width, grid_height, boxes)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3))\n",
    "    \n",
    "    \n",
    "    xpred = y_pred[:, :, :, :, 1]\n",
    "    ypred = y_pred[:, :, :, :, 2]\n",
    "    wpred = y_pred[:, :, :, :, 3]\n",
    "    hpred = y_pred[:, :, :, :, 4]\n",
    "    \n",
    "    box_xpred = (tf.sigmoid(xpred) + cell_x) * cell_width\n",
    "    box_ypred = (tf.sigmoid(ypred) + cell_y) * cell_height\n",
    "    box_wpred = tf.exp(wpred) * anchors[:, 0] * cell_width\n",
    "    box_hpred = tf.exp(hpred) * anchors[:, 1] * cell_height\n",
    "    \n",
    "    \n",
    "    box_wpredhalf = box_wpred / 2\n",
    "    box_hpredhalf = box_hpred / 2\n",
    "    \n",
    "    box_xpredmin = box_xpred - box_wpredhalf\n",
    "    box_xpredmax = box_xpred + box_wpredhalf\n",
    "    box_ypredmin = box_ypred - box_hpredhalf\n",
    "    box_ypredmax = box_ypred + box_hpredhalf\n",
    "    \n",
    "    \n",
    "    box_xtrue = y_true[:, :, :, :, 1]\n",
    "    box_ytrue = y_true[:, :, :, :, 2]\n",
    "    box_wtrue = y_true[:, :, :, :, 3]\n",
    "    box_htrue = y_true[:, :, :, :, 4]\n",
    "    \n",
    "    box_wtruehalf = box_wtrue / 2\n",
    "    box_htruehalf = box_htrue / 2\n",
    "    \n",
    "    box_xtruemin = box_xtrue - box_wtruehalf\n",
    "    box_xtruemax = box_xtrue + box_wtruehalf\n",
    "    box_ytruemin = box_ytrue - box_htruehalf\n",
    "    box_ytruemax = box_ytrue + box_htruehalf\n",
    "    \n",
    "    interxmins = tf.maximum(box_xpredmin, box_xtruemin)\n",
    "    interymins = tf.maximum(box_ypredmin, box_ytruemin)\n",
    "    interxmaxes = tf.minimum(box_xpredmax, box_xtruemax)\n",
    "    interymaxes = tf.minimum(box_ypredmax, box_ytruemax)\n",
    "    \n",
    "    interareas = tf.maximum(0.0, interxmaxes - interxmins + 1) * tf.maximum(0.0, interymaxes - interymins + 1)\n",
    "    \n",
    "    trueareas = (box_htrue + 1) * (box_wtrue + 1)\n",
    "    predareas = (box_hpred + 1) * (box_wpred + 1)\n",
    "    \n",
    "    ious = interareas / (trueareas + predareas - interareas)\n",
    "    \n",
    "    mask_shape = (batch_size, grid_width, grid_height, boxes)\n",
    "    \n",
    "    objs = tf.ones(shape = (mask_shape)) * object_scale\n",
    "    noobjs = tf.ones(shape = (mask_shape)) * noobject_scale\n",
    "    coords = tf.ones(shape = (mask_shape)) * coord_scale\n",
    "    classes = tf.ones(shape = (mask_shape)) * class_scale\n",
    "    zeros = tf.zeros(shape = (mask_shape))\n",
    "    \n",
    "    objects_present = tf.greater(c_true, 0.0) \n",
    "    confcoef = tf.where(objects_present, objs, noobjs)                \n",
    "    coordcoef = tf.where(objects_present, coords, zeros)\n",
    "    classescoef = tf.where(objects_present, classes, zeros) \n",
    "    \n",
    "    \n",
    "    xtrue = box_xtrue / cell_width - (cell_x + 0.5)\n",
    "    ytrue = box_ytrue / cell_height - (cell_y + 0.5)\n",
    "    wtrue = tf.log(box_wtrue / (cell_width * anchors[:, 0]))\n",
    "    htrue = tf.log(box_htrue / (cell_height * anchors[:, 1]))\n",
    "    \n",
    "    \n",
    "    wtrue = tf.where(objects_present, wtrue, zeros)\n",
    "    htrue = tf.where(objects_present, htrue, zeros)\n",
    "    ious = tf.where(objects_present, ious, zeros)\n",
    "       \n",
    "        \n",
    "    classestrue = tf.argmax(y_true[:, :, :, :, 5:], -1)\n",
    "    classespred = tf.nn.softmax(y_pred[:, :, :, :, 5:])\n",
    "    \n",
    "    classesloss = classescoef * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=classestrue, logits=classespred)\n",
    "    \n",
    "    \n",
    "    confloss = confcoef * ((ious - c_pred) ** 2)\n",
    "    \n",
    "    xloss = coordcoef * ((xtrue - xpred) ** 2)\n",
    "    yloss = coordcoef * ((ytrue - ypred) ** 2)\n",
    "    \n",
    "    wloss = coordcoef * ((wtrue - wpred) ** 2)\n",
    "    hloss = coordcoef * ((htrue - hpred) ** 2)\n",
    "    \n",
    "    coordloss = xloss + yloss + wloss + hloss\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = confloss + coordloss + classesloss  \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def decode_prediction(y_pred, onlyconf = False):\n",
    "    objects = []\n",
    "    accepted = 0\n",
    "    rejected = 0\n",
    "    \n",
    "    for row in range(grid_height):\n",
    "        for col in range(grid_width):\n",
    "            for box in range(boxes):\n",
    "                to, tx, ty, tw, th = y_pred[row, col, box, :5]\n",
    "                \n",
    "                \n",
    "                conf = sigmoid(to) \n",
    "                labels = y_pred[row, col, box, 5:]\n",
    "                labels = softmax(labels)\n",
    "                \n",
    "                max_label = max(labels)\n",
    "\n",
    "                conf *= max_label\n",
    "                \n",
    "                               \n",
    "                #if conf >= threshhold and row == 3 and col == 3:\n",
    "                if conf >= threshhold:\n",
    "                    max_index = -1\n",
    "                    for i in range(len(labels)):\n",
    "                        if labels[i] == max_label:\n",
    "                            max_index = i\n",
    "                            break\n",
    "                    \n",
    "                    label = encoder.decode(max_index)\n",
    "                    accepted+=1\n",
    "                    #print(f'row: {row} col: {col} box: {box}')\n",
    "                    if onlyconf:\n",
    "                        bx = (col + 0.5) * cell_width\n",
    "                        by = (row + 0.5) * cell_height\n",
    "\n",
    "                        pw, ph = anchors[box]\n",
    "\n",
    "                        bw = pw * cell_width\n",
    "                        bh = ph * cell_height\n",
    "\n",
    "                        #bw *= cell_width\n",
    "                        #bh *= cell_height\n",
    "                    else:\n",
    "                        bx = (sigmoid(tx) + col) * grid_width\n",
    "                        by = (sigmoid(ty) + row) * grid_width\n",
    "\n",
    "                        pw, ph = anchors[box]\n",
    "\n",
    "                        bw = pw * np.exp(tw)\n",
    "                        bh = ph * np.exp(tw)\n",
    "\n",
    "                        bw *= cell_width\n",
    "                        bh *= cell_height\n",
    "                    \n",
    "                    objects.append(Object(xmin = bx - bw/2, xmax = bx + bw/2, ymin = by - bh/2, ymax = by + bh/2, conf = conf, name = label))\n",
    "                else:\n",
    "                    rejected+=1\n",
    "                    \n",
    "    print(f'accepted: {accepted}, rejected: {rejected}')\n",
    "    return objects\n",
    "\n",
    "\n",
    "def nms(objects):\n",
    "    if len(objects) == 0:\n",
    "        return []\n",
    "    \n",
    "    objects = sorted(objects, key = lambda obj: obj.conf, reverse = True)\n",
    "    \n",
    "    result = [objects[0]]\n",
    "    del objects[0]\n",
    "    \n",
    "    for i, obj in enumerate(objects):\n",
    "        for res in result:\n",
    "            if calculate_IoU(obj, res) > nms_threshhold:\n",
    "                del objects[i]\n",
    "                break\n",
    "        else:\n",
    "            result.append(obj)\n",
    "            del objects[i]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def group_nms(objects):\n",
    "    keys = set(map(lambda obj: obj.name, objects))\n",
    "    groups = dict()\n",
    "    \n",
    "    for key in keys:\n",
    "        groups[key] = []\n",
    "    for obj in objects:\n",
    "        groups[obj.name].append(obj)\n",
    "    \n",
    "    result = []\n",
    "    for key in keys:\n",
    "        result.extend(nms(groups[key]))        \n",
    "    \n",
    "    return result\n",
    "\n",
    "def feed_forward(model, image_path, draw = False):\n",
    "    im = Img.open(image_path)\n",
    "    \n",
    "    width_scale = im.width / image_width\n",
    "    height_scale = im.height / image_height \n",
    "    \n",
    "    im = im.resize((image_width, image_height))\n",
    "    im = np.array(im, np.float32)\n",
    "    im /= 255\n",
    "    \n",
    "    y_pred = model.predict(np.array([im]))[0]\n",
    "    \n",
    "    objects = decode_prediction(y_pred, True)\n",
    "    \n",
    "    for obj in objects:\n",
    "              \n",
    "        \n",
    "        w = obj.xmax - obj.xmin\n",
    "        h = obj.ymax - obj.ymin\n",
    "        #w *= grid_width\n",
    "        #h *= grid_height\n",
    "        \n",
    "        xmid = (obj.xmax - obj.xmin) / 2\n",
    "        ymid = (obj.ymax - obj.ymin) / 2\n",
    "        \n",
    "        #obj.xmin = xmid - w/2\n",
    "        #obj.xmax = xmid + w/2\n",
    "        #obj.ymin = ymid - h/2\n",
    "        #obj.ymax = ymid + h/2\n",
    "        \n",
    "        \n",
    "        \n",
    "        obj.xmin *= width_scale\n",
    "        obj.xmax *= width_scale\n",
    "        obj.ymin *= height_scale\n",
    "        obj.ymax *= height_scale\n",
    "        \n",
    "        \n",
    "        \n",
    "        #obj.xmin = obj.xmin * image_cell_width\n",
    "        #obj.xmax = obj.xmax * image_cell_width\n",
    "        #obj.ymin = obj.ymin * image_cell_height\n",
    "        #obj.ymax = obj.ymax * image_cell_height\n",
    "        \n",
    "    if draw:\n",
    "        draw_image(image_path, objects, draw_grid = True, grid_size = (grid_width, grid_height))\n",
    "    \n",
    "    return objects\n",
    "\n",
    "#feed_forward(mobilenetyolov2, runningman)\n",
    "#feed_forward(tinyyolov2, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lens: 5011 5011\n",
      "Prepared ins & outs paths\n"
     ]
    }
   ],
   "source": [
    "annotations_files, images = get_annotations_images(annotation_folder, images_folder)\n",
    "#ins = np.array([image_to_mobilenet_input(image, inputshape = (image_width, image_height)) for image in images], dtype=np.float32)\n",
    "#outs = np.array([encode_y_true_from_annotatoin(annotation) for annotation in annotations], dtype=np.float32)\n",
    "\n",
    "#print(ins.shape)\n",
    "#print(outs.shape)\n",
    "print(f'Lens: {len(annotations_files)} {len(images)}')\n",
    "print('Prepared ins & outs paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared annotations in 1.20s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "annotations = [parse_annotation(annotation) for annotation in annotations_files]\n",
    "end = time.time()\n",
    "\n",
    "print(f'Prepared annotations in {(end - start):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(annotations, images, batch_size, raw_files = True):\n",
    "    ins = []\n",
    "    outs = []\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        for index in range(len(images)):\n",
    "            # TODO: Image augmentation\n",
    "            ins.append(image_to_mobilenet_input(images[index], inputshape = (image_width, image_height)))\n",
    "            outs.append(encode_y_true_from_annotation(annotations[index], raw_files))\n",
    "            \n",
    "            if len(ins) == batch_size:\n",
    "                yield (np.array(ins, dtype=np.float32), np.array(outs, dtype=np.float32))\n",
    "                ins = []\n",
    "                outs = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert not np.any(np.isnan(ins))\n",
    "#assert not np.any(np.isnan(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch generated in 1.15s\n"
     ]
    }
   ],
   "source": [
    "generator_preprocessed = batch_generator(annotations, images, batch_size, raw_files=False)\n",
    "\n",
    "start = time.time()\n",
    "next(generator_preprocessed)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Batch generated in {(end - start):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch generated in 1.23s\n"
     ]
    }
   ],
   "source": [
    "generator_raw = batch_generator(annotations_files, images, batch_size, raw_files=True)\n",
    "\n",
    "start = time.time()\n",
    "next(generator_raw)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Batch generated in {(end - start):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's not a significant enough time difference for pre-loading of annotations to be worth it.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''There's not a significant enough time difference for pre-loading of annotations to be worth it.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image prepared in: 0.00700s\n",
      "Image prepared in: 0.00700s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"There's not a significant time difference when using opencv.\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_to_mobilenet_input_opencv(path, inputshape):\n",
    "    im = cv2.imread(path)\n",
    "    im = cv2.resize(im, inputshape)\n",
    "    \n",
    "    im = np.array(im, np.float32)\n",
    "    im = im[..., ::-1]\n",
    "    im /= 255\n",
    "    im -= 0.5\n",
    "    im *= 2.\n",
    "    \n",
    "    return im\n",
    "\n",
    "start = time.time()\n",
    "a = image_to_mobilenet_input_opencv(test_image, inputshape = (image_width, image_height))\n",
    "end = time.time()\n",
    "\n",
    "print(f'Image prepared in: {(end - start):.5f}s')\n",
    "\n",
    "start = time.time()\n",
    "b = image_to_mobilenet_input(test_image, inputshape = (image_width, image_height))\n",
    "end = time.time()\n",
    "\n",
    "print(f'Image prepared in: {(end - start):.5f}s')\n",
    "'''There's not a significant time difference when using opencv.'''\n",
    "#assert np.array_equal(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a[0])\n",
    "#print('==================')\n",
    "#print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenetyolov2():\n",
    "    mobilenetyolov2 = MobileNet(weights ='imagenet', include_top = False, input_shape=(image_width, image_height, 3))\n",
    "    mobilenetyolov2.trainable = False\n",
    "    layers = mobilenetyolov2.layers[:]\n",
    "\n",
    "    layers.append(Conv2D(filters = (boxes * (4 + 1 + labels_count)), kernel_size = (1, 1), padding = \"same\", name=\"conv_output\"))\n",
    "    layers.append(Reshape(target_shape = (grid_width, grid_height, boxes, 5 + labels_count), name = \"output\"))\n",
    "\n",
    "    mobilenetyolov2 = Sequential(layers = layers, name = \"yolov2 mobilenetv2\")\n",
    "    #mobilenetyolov2.summary()\n",
    "    \n",
    "    return mobilenetyolov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetyolov2 = get_mobilenetyolov2()\n",
    "\n",
    "adam = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "mobilenetyolov2.compile(optimizer = adam, loss = custom_loss)\n",
    "\n",
    "print('Model compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testbatchins = ins[:batch_size]\n",
    "#testbatchouts = outs[:batch_size]\n",
    "#testbatchins = np.array([image_to_mobilenet_input(test_image, (image_width, image_height))], dtype=np.float32)\n",
    "#testbatchouts = np.array([encode_y_true_from_annotatoin(test_annotation)], dtype=np.float32)\n",
    "    \n",
    "#pred = mobilenetyolov2.predict(testbatchins)\n",
    "#loss = custom_loss(testbatchouts, pred)\n",
    "\n",
    "#assert not np.any(np.isnan(pred))\n",
    "#assert not np.any(np.isnan(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetyolov2.load_weights('./weights/mobilenetyolov2try06750epochson5000dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "epochs = 750\n",
    "\n",
    "h = mobilenetyolov2.fit_generator(batch_generator(annotations, images, batch_size), steps_per_epoch = len(images) // batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetyolov2.save_weights('./weights/mobilenetyolov2try06750epochson5000dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshhold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshhold = 0.2\n",
    "objs = feed_forward(mobilenetyolov2, images[index], True)\n",
    "for obj in objs:\n",
    "    print(obj)\n",
    "objects_trough_nms = group_nms(objs)\n",
    "draw_image(images[index], objects_trough_nms, draw_grid = True, grid_size = (grid_width, grid_height))\n",
    "for obj in objects_trough_nms:\n",
    "    print(obj)\n",
    "threshhold = 0.5\n",
    "index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#index = 52\n",
    "#runningman = images[52]\n",
    "'''\n",
    "encoded = encode_y_true_from_annotatoin(annotations[index])\n",
    "for row in range(grid_width):\n",
    "    for col in range(grid_height):\n",
    "        for box in range(boxes):\n",
    "            if encoded[row, col, box, 0]== 1:\n",
    "                print(f'{row} {col} {box}')\n",
    "'''\n",
    "\n",
    "threshhold = 0.2\n",
    "objs = feed_forward(mobilenetyolov2, murka, False)\n",
    "objs = nms(objs)\n",
    "for obj in objs:\n",
    "    print(obj)\n",
    "draw_image(murka, objs)\n",
    "threshhold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "things to consider:\n",
    "Lambda layer which decodes output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "       \n",
    "    training:\n",
    "        what happens when two objects have the same box - pick one at random. better luck next epoch!\n",
    "        \n",
    "    possible consideration:\n",
    "        if the network makes a prediction with an IoU > 0.6 in a detector which was not chosen for the object do not penalise it\n",
    "      \n",
    "    image augmentation:\n",
    "        decide what to do as augmentation\n",
    "        implement it\n",
    "    \n",
    "    \n",
    "    apply comparing of predicted object type in nms?\n",
    "    take confidence into consideration nms\n",
    "    \n",
    "    train on entire voc 2012 + 2007 not only 2007 and not only 250 images\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = MobileNet(weights ='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('n02123045', 'tabby', 0.36844376), ('n02123159', 'tiger_cat', 0.22896749), ('n02098286', 'West_Highland_white_terrier', 0.067757644), ('n02124075', 'Egyptian_cat', 0.052789785), ('n01675722', 'banded_gecko', 0.02626083)]]\n"
     ]
    }
   ],
   "source": [
    "'''Sanity check if images are preprocessed correctly for mobilenet'''\n",
    "#from tensorflow.keras.applications.mobilenet import decode_predictions\n",
    "\n",
    "#test = np.array([image_to_mobilenet_input(r'.\\VOCdevkit\\VOC2007\\JPEGImages\\000019.jpg', inputshape=(224, 224))])\n",
    "#res = mobilenet.predict(test)\n",
    "#print(decode_predictions(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
